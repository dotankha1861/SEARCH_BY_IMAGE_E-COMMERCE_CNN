{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aq-JihU82T-l"
      },
      "source": [
        "# **TÌM KIẾM SẢN PHẨM BẰNG HÌNH ẢNH HUẤN LUYỆN VỚI MÔ HÌNH CNN**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jygUSEaKNADS"
      },
      "source": [
        "## **CONNECT TO DRIVE AND DECLARE PARAMS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJ8TRpx5H9um",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90d8cd31-f532-4ed1-9782-ea9147d2ebda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from keras.models import model_from_json\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "def get_path_label(labels):\n",
        "    return os.path.join(label_path,\"le_\" + \"_\".join(labels) + \".npy\")\n",
        "\n",
        "def get_path_model_json(labels):\n",
        "    return os.path.join(model_path,\"model_\" + \"_\".join(labels) + \".json\")\n",
        "\n",
        "def get_path_model_h5(labels):\n",
        "    return os.path.join(model_path,\"weight_\" + \"_\".join(labels) + \".h5\")\n",
        "\n",
        "def load_model(labels):\n",
        "    json_file = open(get_path_model_json(labels), 'r')\n",
        "    loaded_model_json = json_file.read()\n",
        "    json_file.close()\n",
        "    model = model_from_json(loaded_model_json)\n",
        "    model.load_weights(get_path_model_h5(labels))\n",
        "    return model\n",
        "\n",
        "# path dir\n",
        "orgdata_path = os.path.join(\"/content/drive/MyDrive/HTTM/dataset_org\")\n",
        "stddata_path = os.path.join(\"/content/drive/MyDrive/HTTM/dataset_std\")\n",
        "incdata_path = os.path.join(\"/content/drive/MyDrive/HTTM/dataset_inc\")\n",
        "model_path   = os.path.join(\"/content/drive/MyDrive/HTTM/model\")\n",
        "label_path   = os.path.join(\"/content/drive/MyDrive/HTTM/label\")\n",
        "\n",
        "# normalized image\n",
        "size = (64, 64)\n",
        "nchanels = 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrxZvFrQNQ3o"
      },
      "source": [
        "## **CREATING AUGMENTED DATASET**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPGx8ArZMN5p",
        "outputId": "b2518e50-6bec-4306-904d-b6d09ac355f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing dir /content/drive/MyDrive/HTTM/dataset_std\n",
            "Creating folder washing_machine...\n",
            "   Creating folder mg01... OK!\n",
            "   Creating folder mg02... OK!\n",
            "   Creating folder mg03... OK!\n",
            "   Creating folder mg04... OK!\n",
            "   Creating folder mg05... OK!\n",
            "   Creating folder mg06... OK!\n",
            "   Creating folder mg07... OK!\n",
            "   Creating folder mg08... OK!\n",
            "   Creating folder mg09... OK!\n",
            "   Creating folder mg10... OK!\n",
            "Creating folder fridge...\n",
            "   Creating folder tl06... OK!\n",
            "   Creating folder tl05... OK!\n",
            "   Creating folder tl03... OK!\n",
            "   Creating folder tl02... OK!\n",
            "   Creating folder tl04... OK!\n",
            "   Creating folder tl01... OK!\n",
            "   Creating folder tl07... OK!\n",
            "   Creating folder tl09... OK!\n",
            "   Creating folder tl10... OK!\n",
            "   Creating folder tl08... OK!\n",
            "Creating folder blender...\n",
            "   Creating folder mx06... OK!\n",
            "   Creating folder mx03... OK!\n",
            "   Creating folder mx04... OK!\n",
            "   Creating folder mx02... OK!\n",
            "   Creating folder mx08... OK!\n",
            "   Creating folder mx09... OK!\n",
            "   Creating folder mx05... OK!\n",
            "   Creating folder mx10... OK!\n",
            "   Creating folder mx01... OK!\n",
            "   Creating folder mx07... OK!\n",
            "Creating folder cooker...\n",
            "   Creating folder ncd10... OK!\n",
            "   Creating folder ncd09... OK!\n",
            "   Creating folder ncd08... OK!\n",
            "   Creating folder ncd07... OK!\n",
            "   Creating folder ncd06... OK!\n",
            "   Creating folder ncd03... OK!\n",
            "   Creating folder ncd04... OK!\n",
            "   Creating folder ncd02... OK!\n",
            "   Creating folder ncd01... OK!\n",
            "   Creating folder ncd05... OK!\n",
            "Creating folder vacuum...\n",
            "   Creating folder mhb10... OK!\n",
            "   Creating folder mhb09... OK!\n",
            "   Creating folder mhb08... OK!\n",
            "   Creating folder mhb07... OK!\n",
            "   Creating folder mhb06... OK!\n",
            "   Creating folder mhb05... OK!\n",
            "   Creating folder mhb04... OK!\n",
            "   Creating folder mhb02... OK!\n",
            "   Creating folder mhb03... OK!\n",
            "   Creating folder mhb01... OK!\n",
            "Completed!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import shutil\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from numpy import expand_dims\n",
        "\n",
        "num_aug_data = 10\n",
        "\n",
        "# load_data:\n",
        "print('Writing dir', stddata_path)\n",
        "for folder in os.listdir(orgdata_path):\n",
        "\n",
        "    curr_path = os.path.join(orgdata_path, folder)\n",
        "    save_path = os.path.join(stddata_path, folder)\n",
        "\n",
        "    try:\n",
        "        os.mkdir(save_path)\n",
        "    except:\n",
        "        shutil.rmtree(save_path)\n",
        "        os.mkdir(save_path)\n",
        "\n",
        "    print('Creating folder', folder + '...')\n",
        "\n",
        "    for _folder in os.listdir(curr_path):\n",
        "\n",
        "        _curr_path = os.path.join(curr_path, _folder)\n",
        "        _save_path = os.path.join(save_path, _folder)\n",
        "\n",
        "        os.mkdir(_save_path)\n",
        "\n",
        "        print('   Creating folder', _folder + '...', end = ' ')\n",
        "\n",
        "        for file in os.listdir(_curr_path):\n",
        "            curr_file = os.path.join(_curr_path,file)\n",
        "\n",
        "            image = cv2.imread(curr_file)\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "            image = cv2.resize(image, dsize = size, interpolation= cv2.INTER_LINEAR)\n",
        "            image = expand_dims(image, axis = 0)\n",
        "\n",
        "            # augment data\n",
        "            myImageGen = ImageDataGenerator(width_shift_range=[-5,5], height_shift_range=[-5,5], rotation_range=10, shear_range=10)\n",
        "            gen = myImageGen.flow(image, batch_size=1)\n",
        "\n",
        "            for i in range(num_aug_data):\n",
        "                myBatch = gen.next()\n",
        "\n",
        "                I = myBatch[0].astype('uint8')\n",
        "\n",
        "                path_save = os.path.join(_save_path, file[:file.find('.')] + '_aug_' + str(i) + '_' + file[file.find('.'):])\n",
        "                cv2.imwrite(path_save, I)\n",
        "\n",
        "        print('OK!')\n",
        "print('Completed!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDw_Ke4sDDBK"
      },
      "source": [
        "## **CREATING INCORRECT DATASET**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Utp-fLIrDBTH",
        "outputId": "4546f338-e0af-40cf-e2e5-da5d5e00731d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading dir /content/drive/MyDrive/HTTM/dataset_std\n",
            "Reading folder washing_machine...\n",
            "   Reading folder mg01... OK!\n",
            "   Reading folder mg02... OK!\n",
            "   Reading folder mg03... OK!\n",
            "   Reading folder mg04... OK!\n",
            "   Reading folder mg05... OK!\n",
            "   Reading folder mg06... OK!\n",
            "   Reading folder mg07... OK!\n",
            "   Reading folder mg08... OK!\n",
            "   Reading folder mg09... OK!\n",
            "   Reading folder mg10... OK!\n",
            "Reading folder fridge...\n",
            "   Reading folder tl06... OK!\n",
            "   Reading folder tl05... OK!\n",
            "   Reading folder tl03... OK!\n",
            "   Reading folder tl02... OK!\n",
            "   Reading folder tl04... OK!\n",
            "   Reading folder tl01... OK!\n",
            "   Reading folder tl07... OK!\n",
            "   Reading folder tl09... OK!\n",
            "   Reading folder tl10... OK!\n",
            "   Reading folder tl08... OK!\n",
            "Reading folder blender...\n",
            "   Reading folder mx06... OK!\n",
            "   Reading folder mx03... OK!\n",
            "   Reading folder mx04... OK!\n",
            "   Reading folder mx02... OK!\n",
            "   Reading folder mx08... OK!\n",
            "   Reading folder mx09... OK!\n",
            "   Reading folder mx05... OK!\n",
            "   Reading folder mx10... OK!\n",
            "   Reading folder mx01... OK!\n",
            "   Reading folder mx07... OK!\n",
            "Reading folder cooker...\n",
            "   Reading folder ncd10... OK!\n",
            "   Reading folder ncd09... OK!\n",
            "   Reading folder ncd08... OK!\n",
            "   Reading folder ncd07... OK!\n",
            "   Reading folder ncd06... OK!\n",
            "   Reading folder ncd03... OK!\n",
            "   Reading folder ncd04... OK!\n",
            "   Reading folder ncd02... OK!\n",
            "   Reading folder ncd01... OK!\n",
            "   Reading folder ncd05... OK!\n",
            "Reading folder vacuum...\n",
            "   Reading folder mhb10... OK!\n",
            "   Reading folder mhb09... OK!\n",
            "   Reading folder mhb08... OK!\n",
            "   Reading folder mhb07... OK!\n",
            "   Reading folder mhb06... OK!\n",
            "   Reading folder mhb05... OK!\n",
            "   Reading folder mhb04... OK!\n",
            "   Reading folder mhb02... OK!\n",
            "   Reading folder mhb03... OK!\n",
            "   Reading folder mhb01... OK!\n",
            "Writing dir /content/drive/MyDrive/HTTM/dataset_inc\n",
            "Creating folder washing_machine...\n",
            "   Creating folder mg01... OK!\n",
            "   Creating folder mg02... OK!\n",
            "   Creating folder mg03... OK!\n",
            "   Creating folder mg04... OK!\n",
            "   Creating folder mg05... OK!\n",
            "   Creating folder mg06... OK!\n",
            "   Creating folder mg07... OK!\n",
            "   Creating folder mg08... OK!\n",
            "   Creating folder mg09... OK!\n",
            "   Creating folder mg10... OK!\n",
            "Creating folder fridge...\n",
            "   Creating folder tl06... OK!\n",
            "   Creating folder tl05... OK!\n",
            "   Creating folder tl03... OK!\n",
            "   Creating folder tl02... OK!\n",
            "   Creating folder tl04... OK!\n",
            "   Creating folder tl01... OK!\n",
            "   Creating folder tl07... OK!\n",
            "   Creating folder tl09... OK!\n",
            "   Creating folder tl10... OK!\n",
            "   Creating folder tl08... OK!\n",
            "Creating folder blender...\n",
            "   Creating folder mx06... OK!\n",
            "   Creating folder mx03... OK!\n",
            "   Creating folder mx04... OK!\n",
            "   Creating folder mx02... OK!\n",
            "   Creating folder mx08... OK!\n",
            "   Creating folder mx09... OK!\n",
            "   Creating folder mx05... OK!\n",
            "   Creating folder mx10... OK!\n",
            "   Creating folder mx01... OK!\n",
            "   Creating folder mx07... OK!\n",
            "Creating folder cooker...\n",
            "   Creating folder ncd10... OK!\n",
            "   Creating folder ncd09... OK!\n",
            "   Creating folder ncd08... OK!\n",
            "   Creating folder ncd07... OK!\n",
            "   Creating folder ncd06... OK!\n",
            "   Creating folder ncd03... OK!\n",
            "   Creating folder ncd04... OK!\n",
            "   Creating folder ncd02... OK!\n",
            "   Creating folder ncd01... OK!\n",
            "   Creating folder ncd05... OK!\n",
            "Creating folder vacuum...\n",
            "   Creating folder mhb10... OK!\n",
            "   Creating folder mhb09... OK!\n",
            "   Creating folder mhb08... OK!\n",
            "   Creating folder mhb07... OK!\n",
            "   Creating folder mhb06... OK!\n",
            "   Creating folder mhb05... OK!\n",
            "   Creating folder mhb04... OK!\n",
            "   Creating folder mhb02... OK!\n",
            "   Creating folder mhb03... OK!\n",
            "   Creating folder mhb01... OK!\n",
            "Completed!\n"
          ]
        }
      ],
      "source": [
        "images = []\n",
        "\n",
        "print('Reading dir', stddata_path)\n",
        "for folder in os.listdir(stddata_path):\n",
        "\n",
        "    curr_path = os.path.join(stddata_path, folder)\n",
        "\n",
        "    print('Reading folder', folder + '...')\n",
        "\n",
        "    for _folder in os.listdir(curr_path):\n",
        "\n",
        "        _curr_path = os.path.join(curr_path, _folder)\n",
        "\n",
        "        print('   Reading folder', _folder + '...', end = ' ')\n",
        "\n",
        "        for file in os.listdir(_curr_path):\n",
        "            curr_file = os.path.join(_curr_path,file)\n",
        "\n",
        "            image = cv2.imread(curr_file)\n",
        "            images.append(image)\n",
        "\n",
        "        print('OK!')\n",
        "\n",
        "import random\n",
        "random.shuffle(images)\n",
        "\n",
        "print('Writing dir', incdata_path)\n",
        "for folder in os.listdir(stddata_path):\n",
        "\n",
        "    curr_path = os.path.join(stddata_path, folder)\n",
        "    save_path = os.path.join(incdata_path, folder)\n",
        "\n",
        "    try:\n",
        "        os.mkdir(save_path)\n",
        "    except:\n",
        "        shutil.rmtree(save_path)\n",
        "        os.mkdir(save_path)\n",
        "\n",
        "    print('Creating folder', folder + '...')\n",
        "\n",
        "    for _folder in os.listdir(curr_path):\n",
        "\n",
        "        _save_path = os.path.join(save_path, _folder)\n",
        "\n",
        "        os.mkdir(_save_path)\n",
        "\n",
        "        print('   Creating folder', _folder + '...', end = ' ')\n",
        "\n",
        "        for i in range(num_aug_data):\n",
        "\n",
        "            path_save = os.path.join(_save_path, _folder + '_image_' + str(i) + '.jpg')\n",
        "            cv2.imwrite(path_save, images[i])\n",
        "\n",
        "        images = images[num_aug_data:]\n",
        "\n",
        "        print('OK!')\n",
        "\n",
        "print('Completed!')\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zf9RfnnWW03h"
      },
      "source": [
        "# **TRAIN MODEL**\n",
        "- Level = 0 and type_sp = '' : Huấn luyện model đoán loại sản phẩm\n",
        "- Level = 1 and type_sp = '<tên sp>': Huấn luyện model đoán id sản phẩm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFI6VxjcMRXJ",
        "outputId": "f59017a7-e109-485c-f346-2b284efedadd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_84 (Conv2D)          (None, 62, 62, 256)       7168      \n",
            "                                                                 \n",
            " max_pooling2d_84 (MaxPoolin  (None, 31, 31, 256)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_85 (Conv2D)          (None, 29, 29, 128)       295040    \n",
            "                                                                 \n",
            " max_pooling2d_85 (MaxPoolin  (None, 15, 15, 128)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_86 (Conv2D)          (None, 13, 13, 64)        73792     \n",
            "                                                                 \n",
            " max_pooling2d_86 (MaxPoolin  (None, 7, 7, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_87 (Conv2D)          (None, 5, 5, 32)          18464     \n",
            "                                                                 \n",
            " max_pooling2d_87 (MaxPoolin  (None, 3, 3, 32)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_21 (Flatten)        (None, 288)               0         \n",
            "                                                                 \n",
            " dropout_40 (Dropout)        (None, 288)               0         \n",
            "                                                                 \n",
            " dense_61 (Dense)            (None, 1024)              295936    \n",
            "                                                                 \n",
            " dropout_41 (Dropout)        (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_62 (Dense)            (None, 512)               524800    \n",
            "                                                                 \n",
            " dense_63 (Dense)            (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,220,330\n",
            "Trainable params: 1,220,330\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 16s 4s/step - loss: 2.3132 - accuracy: 0.1010 - val_loss: 2.3021 - val_accuracy: 0.1024\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 15s 4s/step - loss: 2.2712 - accuracy: 0.1683 - val_loss: 2.2375 - val_accuracy: 0.2598\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 15s 4s/step - loss: 2.1208 - accuracy: 0.2792 - val_loss: 2.0403 - val_accuracy: 0.3622\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 16s 4s/step - loss: 1.8255 - accuracy: 0.3446 - val_loss: 1.7704 - val_accuracy: 0.3701\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 16s 4s/step - loss: 1.5129 - accuracy: 0.4396 - val_loss: 1.4429 - val_accuracy: 0.4331\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 16s 4s/step - loss: 1.1651 - accuracy: 0.5465 - val_loss: 1.1384 - val_accuracy: 0.5748\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 15s 4s/step - loss: 0.9622 - accuracy: 0.6079 - val_loss: 1.6841 - val_accuracy: 0.3622\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 15s 4s/step - loss: 1.1652 - accuracy: 0.5267 - val_loss: 1.2286 - val_accuracy: 0.5039\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 15s 4s/step - loss: 0.9666 - accuracy: 0.6020 - val_loss: 1.0309 - val_accuracy: 0.5984\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 15s 4s/step - loss: 0.8091 - accuracy: 0.6733 - val_loss: 0.8154 - val_accuracy: 0.6299\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 15s 4s/step - loss: 0.6212 - accuracy: 0.7663 - val_loss: 0.6947 - val_accuracy: 0.7480\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 15s 4s/step - loss: 0.5181 - accuracy: 0.7723 - val_loss: 0.7064 - val_accuracy: 0.7402\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 16s 4s/step - loss: 0.4440 - accuracy: 0.8178 - val_loss: 0.5812 - val_accuracy: 0.8031\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 16s 4s/step - loss: 0.3870 - accuracy: 0.8515 - val_loss: 0.6020 - val_accuracy: 0.7402\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 15s 4s/step - loss: 0.3575 - accuracy: 0.8495 - val_loss: 0.6722 - val_accuracy: 0.7638\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 16s 4s/step - loss: 0.3567 - accuracy: 0.8713 - val_loss: 0.4335 - val_accuracy: 0.8110\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 15s 4s/step - loss: 0.3218 - accuracy: 0.8950 - val_loss: 0.4873 - val_accuracy: 0.8346\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 16s 4s/step - loss: 0.2964 - accuracy: 0.8911 - val_loss: 0.2988 - val_accuracy: 0.9055\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 15s 4s/step - loss: 0.2081 - accuracy: 0.9307 - val_loss: 0.3644 - val_accuracy: 0.9055\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 16s 4s/step - loss: 0.1713 - accuracy: 0.9426 - val_loss: 0.2928 - val_accuracy: 0.8976\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 16s 4s/step - loss: 0.1511 - accuracy: 0.9426 - val_loss: 0.2742 - val_accuracy: 0.8819\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 16s 4s/step - loss: 0.1275 - accuracy: 0.9465 - val_loss: 0.3206 - val_accuracy: 0.8898\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 16s 4s/step - loss: 0.1332 - accuracy: 0.9485 - val_loss: 0.2330 - val_accuracy: 0.9291\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 16s 4s/step - loss: 0.1006 - accuracy: 0.9703 - val_loss: 0.3973 - val_accuracy: 0.8661\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 16s 4s/step - loss: 0.1451 - accuracy: 0.9426 - val_loss: 0.2185 - val_accuracy: 0.9213\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 16s 4s/step - loss: 0.1676 - accuracy: 0.9208 - val_loss: 0.2689 - val_accuracy: 0.9134\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 16s 4s/step - loss: 0.1591 - accuracy: 0.9446 - val_loss: 0.2879 - val_accuracy: 0.9449\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 16s 4s/step - loss: 0.1247 - accuracy: 0.9525 - val_loss: 0.2883 - val_accuracy: 0.9055\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 16s 4s/step - loss: 0.0808 - accuracy: 0.9762 - val_loss: 0.2510 - val_accuracy: 0.9213\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 16s 4s/step - loss: 0.0832 - accuracy: 0.9703 - val_loss: 0.1663 - val_accuracy: 0.9449\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 16s 4s/step - loss: 0.0714 - accuracy: 0.9782 - val_loss: 0.2515 - val_accuracy: 0.9370\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 16s 4s/step - loss: 0.0668 - accuracy: 0.9743 - val_loss: 0.2240 - val_accuracy: 0.9528\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 16s 4s/step - loss: 0.0549 - accuracy: 0.9782 - val_loss: 0.1617 - val_accuracy: 0.9449\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 16s 4s/step - loss: 0.0647 - accuracy: 0.9782 - val_loss: 0.2394 - val_accuracy: 0.9134\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 16s 4s/step - loss: 0.0396 - accuracy: 0.9921 - val_loss: 0.2167 - val_accuracy: 0.9291\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 16s 4s/step - loss: 0.0402 - accuracy: 0.9842 - val_loss: 0.1714 - val_accuracy: 0.9528\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 16s 4s/step - loss: 0.0317 - accuracy: 0.9921 - val_loss: 0.2506 - val_accuracy: 0.9370\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 16s 4s/step - loss: 0.0291 - accuracy: 0.9861 - val_loss: 0.1746 - val_accuracy: 0.9685\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 15s 4s/step - loss: 0.0360 - accuracy: 0.9842 - val_loss: 0.2467 - val_accuracy: 0.9528\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 15s 4s/step - loss: 0.0309 - accuracy: 0.9941 - val_loss: 0.1838 - val_accuracy: 0.9606\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 15s 4s/step - loss: 0.0318 - accuracy: 0.9881 - val_loss: 0.3066 - val_accuracy: 0.9685\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 16s 4s/step - loss: 0.0443 - accuracy: 0.9881 - val_loss: 0.1524 - val_accuracy: 0.9685\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 16s 4s/step - loss: 0.0402 - accuracy: 0.9822 - val_loss: 0.1540 - val_accuracy: 0.9291\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 16s 4s/step - loss: 0.0349 - accuracy: 0.9822 - val_loss: 0.1690 - val_accuracy: 0.9291\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 15s 4s/step - loss: 0.0344 - accuracy: 0.9861 - val_loss: 0.1237 - val_accuracy: 0.9606\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 15s 4s/step - loss: 0.0194 - accuracy: 0.9960 - val_loss: 0.1948 - val_accuracy: 0.9449\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 16s 4s/step - loss: 0.0249 - accuracy: 0.9941 - val_loss: 0.1058 - val_accuracy: 0.9685\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 16s 4s/step - loss: 0.0400 - accuracy: 0.9921 - val_loss: 0.1783 - val_accuracy: 0.9449\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 16s 4s/step - loss: 0.0235 - accuracy: 0.9901 - val_loss: 0.1714 - val_accuracy: 0.9370\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 15s 4s/step - loss: 0.0341 - accuracy: 0.9861 - val_loss: 0.1684 - val_accuracy: 0.9606\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 17s 4s/step - loss: 0.0142 - accuracy: 0.9980 - val_loss: 0.2313 - val_accuracy: 0.9528\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 16s 4s/step - loss: 0.0151 - accuracy: 0.9960 - val_loss: 0.1477 - val_accuracy: 0.9528\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 15s 4s/step - loss: 0.0098 - accuracy: 0.9980 - val_loss: 0.1085 - val_accuracy: 0.9449\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 15s 4s/step - loss: 0.0093 - accuracy: 0.9980 - val_loss: 0.1350 - val_accuracy: 0.9685\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 15s 4s/step - loss: 0.0067 - accuracy: 0.9980 - val_loss: 0.1594 - val_accuracy: 0.9449\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 16s 4s/step - loss: 0.0094 - accuracy: 0.9980 - val_loss: 0.1417 - val_accuracy: 0.9528\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 17s 4s/step - loss: 0.0072 - accuracy: 0.9980 - val_loss: 0.2162 - val_accuracy: 0.9606\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 16s 4s/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.2139 - val_accuracy: 0.9528\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 16s 4s/step - loss: 0.0078 - accuracy: 0.9980 - val_loss: 0.2405 - val_accuracy: 0.9449\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 16s 4s/step - loss: 0.0059 - accuracy: 0.9980 - val_loss: 0.2060 - val_accuracy: 0.9606\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 16s 4s/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.2347 - val_accuracy: 0.9370\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 16s 4s/step - loss: 0.0127 - accuracy: 0.9980 - val_loss: 0.3474 - val_accuracy: 0.9449\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 16s 4s/step - loss: 0.0057 - accuracy: 0.9980 - val_loss: 0.3367 - val_accuracy: 0.9370\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 16s 4s/step - loss: 0.0214 - accuracy: 0.9921 - val_loss: 0.2984 - val_accuracy: 0.9291\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 16s 4s/step - loss: 0.0294 - accuracy: 0.9881 - val_loss: 0.2063 - val_accuracy: 0.9213\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 16s 4s/step - loss: 0.0548 - accuracy: 0.9822 - val_loss: 0.1720 - val_accuracy: 0.9685\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 16s 4s/step - loss: 0.0413 - accuracy: 0.9861 - val_loss: 0.1768 - val_accuracy: 0.9606\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 15s 4s/step - loss: 0.0391 - accuracy: 0.9861 - val_loss: 0.0867 - val_accuracy: 0.9764\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 16s 4s/step - loss: 0.0211 - accuracy: 0.9941 - val_loss: 0.1467 - val_accuracy: 0.9370\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 16s 4s/step - loss: 0.0226 - accuracy: 0.9921 - val_loss: 0.0878 - val_accuracy: 0.9764\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 16s 4s/step - loss: 0.0136 - accuracy: 0.9980 - val_loss: 0.1485 - val_accuracy: 0.9606\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 16s 4s/step - loss: 0.0147 - accuracy: 0.9960 - val_loss: 0.1261 - val_accuracy: 0.9606\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 16s 4s/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.1131 - val_accuracy: 0.9764\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 16s 4s/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.1139 - val_accuracy: 0.9685\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 16s 4s/step - loss: 0.0049 - accuracy: 0.9980 - val_loss: 0.1272 - val_accuracy: 0.9685\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 16s 4s/step - loss: 0.0241 - accuracy: 0.9921 - val_loss: 0.1704 - val_accuracy: 0.9606\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 16s 4s/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2439 - val_accuracy: 0.9606\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 15s 4s/step - loss: 0.0225 - accuracy: 0.9941 - val_loss: 0.1990 - val_accuracy: 0.9685\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 15s 4s/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.2045 - val_accuracy: 0.9606\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 15s 4s/step - loss: 0.0073 - accuracy: 0.9980 - val_loss: 0.2025 - val_accuracy: 0.9449\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 15s 4s/step - loss: 0.0064 - accuracy: 0.9980 - val_loss: 0.2309 - val_accuracy: 0.9528\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 16s 4s/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2430 - val_accuracy: 0.9606\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 16s 4s/step - loss: 0.0080 - accuracy: 0.9960 - val_loss: 0.1540 - val_accuracy: 0.9606\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 15s 4s/step - loss: 0.0139 - accuracy: 0.9941 - val_loss: 0.1950 - val_accuracy: 0.9606\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 16s 4s/step - loss: 0.0186 - accuracy: 0.9921 - val_loss: 0.3107 - val_accuracy: 0.9370\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 16s 4s/step - loss: 0.0187 - accuracy: 0.9941 - val_loss: 0.3615 - val_accuracy: 0.8976\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 16s 4s/step - loss: 0.1482 - accuracy: 0.9545 - val_loss: 0.2163 - val_accuracy: 0.9449\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 15s 4s/step - loss: 0.1551 - accuracy: 0.9446 - val_loss: 0.5630 - val_accuracy: 0.8976\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 16s 4s/step - loss: 0.2450 - accuracy: 0.9366 - val_loss: 0.2411 - val_accuracy: 0.9134\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 16s 4s/step - loss: 0.0866 - accuracy: 0.9782 - val_loss: 0.3150 - val_accuracy: 0.8898\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 15s 4s/step - loss: 0.0622 - accuracy: 0.9861 - val_loss: 0.1764 - val_accuracy: 0.9370\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 15s 4s/step - loss: 0.0418 - accuracy: 0.9881 - val_loss: 0.1504 - val_accuracy: 0.9528\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 15s 4s/step - loss: 0.0274 - accuracy: 0.9901 - val_loss: 0.1398 - val_accuracy: 0.9685\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 15s 4s/step - loss: 0.0258 - accuracy: 0.9960 - val_loss: 0.0907 - val_accuracy: 0.9606\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 15s 4s/step - loss: 0.0135 - accuracy: 0.9960 - val_loss: 0.1503 - val_accuracy: 0.9685\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 16s 4s/step - loss: 0.0267 - accuracy: 0.9901 - val_loss: 0.1979 - val_accuracy: 0.9449\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 15s 4s/step - loss: 0.0205 - accuracy: 0.9960 - val_loss: 0.2152 - val_accuracy: 0.9449\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 16s 4s/step - loss: 0.0069 - accuracy: 0.9980 - val_loss: 0.1881 - val_accuracy: 0.9528\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 15s 4s/step - loss: 0.0123 - accuracy: 0.9960 - val_loss: 0.1612 - val_accuracy: 0.9449\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 15s 4s/step - loss: 0.0079 - accuracy: 0.9980 - val_loss: 0.1780 - val_accuracy: 0.9606\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1121 - accuracy: 0.9684\n",
            "Loss:  0.11205500364303589\n",
            "Acc:  0.9683544039726257\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.utils import to_categorical\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "\n",
        "# params traning\n",
        "epochs = 100\n",
        "batch_size = 128\n",
        "_loss = 'categorical_crossentropy'\n",
        "_optimizer = 'adam'\n",
        "_metrics = ['accuracy']\n",
        "\n",
        "# params loading data\n",
        "'''\n",
        "    level = 0  and type_sp = '': training product type (LEVEL 0)\n",
        "    level = 1  and type_sp = '<product type>': training product id (LEVEL 1)\n",
        "'''\n",
        "level = 1\n",
        "type_sp = 'blender' # '', 'washing_machine', ...\n",
        "\n",
        "# declare vars\n",
        "labels = []\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "# load_data:\n",
        "data_folder = os.path.join(stddata_path, type_sp)\n",
        "for folder in os.listdir(data_folder):\n",
        "\n",
        "    if level == 0:\n",
        "        labels.append(folder)\n",
        "        curr_path = os.path.join(data_folder, folder)\n",
        "    else:\n",
        "        curr_path = data_folder\n",
        "\n",
        "    for _folder in os.listdir(curr_path):\n",
        "        _curr_path = os.path.join(curr_path, _folder)\n",
        "\n",
        "        if level == 1:\n",
        "            labels.append(_folder)\n",
        "\n",
        "        for file in os.listdir(_curr_path):\n",
        "            curr_file = os.path.join(_curr_path,file)\n",
        "\n",
        "            image = cv2.imread(curr_file)\n",
        "\n",
        "            X.append(image)\n",
        "\n",
        "            if level == 0 :\n",
        "                y.append(labels.index(folder))\n",
        "            else:\n",
        "                y.append(labels.index(_folder))\n",
        "\n",
        "    if level == 1:\n",
        "          break\n",
        "\n",
        "# split_data\n",
        "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size = 0.2)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size = 0.2)\n",
        "\n",
        "# limit length of sequences, scaler X in [0,1]\n",
        "X_train = pad_sequences(X_train, maxlen = size[1],dtype = 'float32')/255.0\n",
        "X_val = pad_sequences(X_val, maxlen = X_train.shape[1],dtype = 'float32')/255.0\n",
        "X_test = pad_sequences(X_test, maxlen = X_train.shape[1],dtype = 'float32')/255.0\n",
        "num_classes = len(labels)\n",
        "\n",
        "# one-hot vector\n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "y_val = to_categorical(y_val,num_classes)\n",
        "y_test = to_categorical(y_test,num_classes)\n",
        "\n",
        "# build model\n",
        "model = Sequential()\n",
        "input_size = (size[0], size[1], nchanels)\n",
        "\n",
        "model.add(Conv2D(256, kernel_size=(3, 3),activation='relu', input_shape= input_size))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "\n",
        "model.add(Conv2D(128, kernel_size=(3, 3),activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# compile model\n",
        "model.summary()\n",
        "model.compile(loss = _loss, optimizer = _optimizer, metrics = _metrics)\n",
        "\n",
        "# fit model\n",
        "model.fit(X_train, y_train, epochs = epochs, batch_size = batch_size, validation_data = (X_val, y_val))\n",
        "\n",
        "# save model\n",
        "model.save(os.path.join(model_path, 'weight_' + type_sp + \".h5\"))\n",
        "model_json = model.to_json()\n",
        "with open(os.path.join(model_path, 'model_' + type_sp + \".json\"), 'w') as json_file:\n",
        "    json_file.write(model_json)\n",
        "\n",
        "# save labels\n",
        "import numpy as np\n",
        "np.save(os.path.join(label_path, 'le_' + type_sp + '.npy'), labels, allow_pickle=True)\n",
        "\n",
        "# evaluate model\n",
        "loss, acc = model.evaluate(X_test, y_test)\n",
        "print(\"Loss: \",loss)\n",
        "print(\"Acc: \",acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nTxU9xDcFMQd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d78ef6d7-6049-47fb-cef0-6634f886f5b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "ids: ['tl07', 'tl04', 'tl01', 'tl03', 'tl08', 'tl06', 'tl10', 'tl02', 'tl09', 'tl05']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "\n",
        "def predict(image, labels, is_last):\n",
        "    image = cv2.resize(image, dsize = size, interpolation= cv2.INTER_LINEAR)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = np.expand_dims(image, axis = 0)\n",
        "    image_pad = pad_sequences(image, maxlen = size[1], dtype = 'float32')/255.0\n",
        "    model = load_model(labels)\n",
        "    pred = model.predict(image_pad)\n",
        "    dict_labels = np.load(get_path_label(labels), allow_pickle=True)\n",
        "    if is_last == False:\n",
        "        return dict_labels[np.argmax(pred)]\n",
        "    else:\n",
        "        return dict_labels, pred.tolist()[0]\n",
        "\n",
        "def predict_final(image, num_level = 2):\n",
        "    labels = []\n",
        "    for i in range(0,num_level):\n",
        "        if i < num_level - 1:\n",
        "            label = predict(image, labels, is_last = False)\n",
        "            labels.append(label)\n",
        "        else:\n",
        "            dict_labels, pred = predict(image, labels, is_last = True)\n",
        "            key_sm = [(dict_labels[i],pred[i]) for i in range(len(pred))]\n",
        "            return [x[0] for x in sorted(key_sm, key = lambda x: x[1], reverse=True)]\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    image = cv2.imread(\"/content/drive/MyDrive/HTTM/dataset_org/fridge/tl07/tl07_2.jpg\")\n",
        "    print(\"ids:\", predict_final(image, 2))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **TEST MODEL**"
      ],
      "metadata": {
        "id": "OjVraq2vt-po"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras_preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "def load_data(typePro, path):\n",
        "\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    labels = np.load(get_path_label(typePro), allow_pickle=True).tolist()\n",
        "\n",
        "    data_folder = os.path.join(path, typePro[0])\n",
        "    for folder in os.listdir(data_folder):\n",
        "\n",
        "        if typePro[0] == '':\n",
        "            curr_path = os.path.join(data_folder, folder)\n",
        "        else:\n",
        "            curr_path = data_folder\n",
        "\n",
        "        for _folder in os.listdir(curr_path):\n",
        "            _curr_path = os.path.join(curr_path, _folder)\n",
        "\n",
        "            for file in os.listdir(_curr_path):\n",
        "                curr_file = os.path.join(_curr_path,file)\n",
        "\n",
        "                image = cv2.imread(curr_file)\n",
        "\n",
        "                X.append(image)\n",
        "\n",
        "                if typePro[0] == '':\n",
        "                    y.append(labels.index(folder))\n",
        "                else:\n",
        "                    y.append(labels.index(_folder))\n",
        "\n",
        "        if typePro[0] != '':\n",
        "            break\n",
        "\n",
        "    X = pad_sequences(X, maxlen = size[1],dtype = 'float32')/255.0\n",
        "    y = to_categorical(y, len(labels))\n",
        "\n",
        "    return X, y\n",
        "\n",
        "def Evaluate():\n",
        "\n",
        "    Pre_Products = [['']]\n",
        "    Pre_Products.extend([[product] for product in os.listdir(stddata_path)])\n",
        "\n",
        "    df = pd.DataFrame(index = ['std_dataset', 'inc_dataset'],\n",
        "                      columns= ['loss', 'accuracy'])\n",
        "\n",
        "    for product in Pre_Products:\n",
        "\n",
        "        model = load_model(product)\n",
        "        model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "\n",
        "        X_std, y_std = load_data(product, stddata_path)\n",
        "        X_inc, y_inc = load_data(product, incdata_path)\n",
        "\n",
        "        loss_std, acc_std = model.evaluate(X_std, y_std)\n",
        "        loss_inc, acc_inc = model.evaluate(X_inc, y_inc)\n",
        "\n",
        "        df['loss'] = [loss_std, loss_inc]\n",
        "        df['accuracy'] = [acc_std, acc_inc]\n",
        "\n",
        "        if product[0] == '':\n",
        "            print('Evaluate model predict typePro: ')\n",
        "        else:\n",
        "            print('Evaluate model predict idPro<%s>: '%(product[0]))\n",
        "\n",
        "        print(df, end = '\\n\\n')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    Evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJ6gR4TWt8tD",
        "outputId": "cadbf945-a069-476d-987d-b6d354cc30f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "128/128 [==============================] - 51s 393ms/step - loss: 0.0817 - accuracy: 0.9785\n",
            "16/16 [==============================] - 6s 381ms/step - loss: 18.4530 - accuracy: 0.1520\n",
            "Evaluate model predict typePro: \n",
            "                  loss  accuracy\n",
            "std_dataset   0.081694  0.978484\n",
            "inc_dataset  18.453041  0.152000\n",
            "\n",
            "27/27 [==============================] - 11s 386ms/step - loss: 0.0853 - accuracy: 0.9750\n",
            "4/4 [==============================] - 1s 294ms/step - loss: 13.5499 - accuracy: 0.0700\n",
            "Evaluate model predict idPro<washing_machine>: \n",
            "                  loss  accuracy\n",
            "std_dataset   0.085254     0.975\n",
            "inc_dataset  13.549906     0.070\n",
            "\n",
            "24/24 [==============================] - 9s 379ms/step - loss: 0.1037 - accuracy: 0.9787\n",
            "4/4 [==============================] - 1s 278ms/step - loss: 18.0187 - accuracy: 0.1000\n",
            "Evaluate model predict idPro<fridge>: \n",
            "                  loss  accuracy\n",
            "std_dataset   0.103676  0.978667\n",
            "inc_dataset  18.018713  0.100000\n",
            "\n",
            "25/25 [==============================] - 10s 386ms/step - loss: 0.0516 - accuracy: 0.9873\n",
            "4/4 [==============================] - 1s 274ms/step - loss: 12.4750 - accuracy: 0.0900\n",
            "Evaluate model predict idPro<blender>: \n",
            "                  loss  accuracy\n",
            "std_dataset   0.051648  0.987342\n",
            "inc_dataset  12.475022  0.090000\n",
            "\n",
            "26/26 [==============================] - 10s 387ms/step - loss: 0.0204 - accuracy: 0.9964\n",
            "4/4 [==============================] - 1s 281ms/step - loss: 14.6825 - accuracy: 0.0500\n",
            "Evaluate model predict idPro<cooker>: \n",
            "                  loss  accuracy\n",
            "std_dataset   0.020405  0.996386\n",
            "inc_dataset  14.682525  0.050000\n",
            "\n",
            "28/28 [==============================] - 11s 391ms/step - loss: 0.0773 - accuracy: 0.9886\n",
            "4/4 [==============================] - 1s 283ms/step - loss: 15.2177 - accuracy: 0.0900\n",
            "Evaluate model predict idPro<vacuum>: \n",
            "                  loss  accuracy\n",
            "std_dataset   0.077322  0.988636\n",
            "inc_dataset  15.217699  0.090000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y__av-xWOQc5"
      },
      "source": [
        "# **RUN SERVER**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UGpDdIn1OJ59"
      },
      "outputs": [],
      "source": [
        "from fastapi import FastAPI\n",
        "from predict import predict_final\n",
        "import uvicorn\n",
        "import cv2\n",
        "\n",
        "app = FastAPI()\n",
        "@app.get(\"/submit/\")\n",
        "async def submit(path: str):\n",
        "    image = cv2.imread(path)\n",
        "    pred = predict_final(image)\n",
        "    return {'ids':pred}\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    uvicorn.run(app, host = '127.0.0.1', port = 8080)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}